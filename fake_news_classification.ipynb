{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae0887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf4d9bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huzef\\AppData\\Local\\Temp\\ipykernel_6136\\2045608207.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('Fake_News.csv', encoding='ISO-8859-1', usecols=['title', 'text', 'label'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMAâS ATTORNEY GENERAL SAYS ...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1                                                NaN   \n",
       "2  UNBELIEVABLE! OBAMAâS ATTORNEY GENERAL SAYS ...   \n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text label  \n",
       "0  No comment is expected from Barack Obama Membe...     1  \n",
       "1     Did they post their votes for Hillary already?     1  \n",
       "2   Now, most of the demonstrators gathered last ...     1  \n",
       "3  A dozen politically active pastors came here f...     0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Fake_News.csv', encoding='ISO-8859-1', usecols=['title', 'text', 'label'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83a098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc99d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    2961\n",
       "text     3609\n",
       "label    4321\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e9796c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78097, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d6d1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f9bada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73177, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a93ce07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73177, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.drop('label',axis=1)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f917e766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73177,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['label']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c4d05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3c4eff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding ,Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM , Bidirectional\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4bfd3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size=70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5391f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg=x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9634ae96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a8686202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LAW ENFORCEMENT ON HIGH ALERT Following Threats Against Cops And Whites On 9-11By #BlackLivesMatter And #FYF911 Terrorists [VIDEO]'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "09ce04c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMAâS ATTORNEY GENERAL SAYS ...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
       "      <td>All we can say on this one is it s about time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78092</th>\n",
       "      <td>Russians steal research on Trump in hack of U....</td>\n",
       "      <td>WASHINGTON (Reuters) - Hackers believed to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78093</th>\n",
       "      <td>WATCH: Giuliani Demands That Democrats Apolog...</td>\n",
       "      <td>You know, because in fantasyland Republicans n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78094</th>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78095</th>\n",
       "      <td>Trump tussle gives unpopular Mexican leader mu...</td>\n",
       "      <td>MEXICO CITY (Reuters) - Donald Trumpâs comba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78096</th>\n",
       "      <td>Goldman Sachs Endorses Hillary Clinton For Pre...</td>\n",
       "      <td>Goldman Sachs Endorses Hillary Clinton For Pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "2      UNBELIEVABLE! OBAMAâS ATTORNEY GENERAL SAYS ...   \n",
       "3      Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4      SATAN 2: Russia unvelis an image of its terrif...   \n",
       "5      About Time! Christian Group Sues Amazon and SP...   \n",
       "...                                                  ...   \n",
       "78092  Russians steal research on Trump in hack of U....   \n",
       "78093   WATCH: Giuliani Demands That Democrats Apolog...   \n",
       "78094  Migrants Refuse To Leave Train At Refugee Camp...   \n",
       "78095  Trump tussle gives unpopular Mexican leader mu...   \n",
       "78096  Goldman Sachs Endorses Hillary Clinton For Pre...   \n",
       "\n",
       "                                                    text  \n",
       "0      No comment is expected from Barack Obama Membe...  \n",
       "2       Now, most of the demonstrators gathered last ...  \n",
       "3      A dozen politically active pastors came here f...  \n",
       "4      The RS-28 Sarmat missile, dubbed Satan 2, will...  \n",
       "5      All we can say on this one is it s about time ...  \n",
       "...                                                  ...  \n",
       "78092  WASHINGTON (Reuters) - Hackers believed to be ...  \n",
       "78093  You know, because in fantasyland Republicans n...  \n",
       "78094  Migrants Refuse To Leave Train At Refugee Camp...  \n",
       "78095  MEXICO CITY (Reuters) - Donald Trumpâs comba...  \n",
       "78096  Goldman Sachs Endorses Hillary Clinton For Pre...  \n",
       "\n",
       "[73177 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9f8dfee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#msg.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "75908992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0cea73",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7114f947",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m rev\u001b[38;5;241m=\u001b[39mrev\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      7\u001b[0m rev\u001b[38;5;241m=\u001b[39mrev\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m----> 8\u001b[0m rev\u001b[38;5;241m=\u001b[39m[ps\u001b[38;5;241m.\u001b[39mstem(word)\u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m rev \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      9\u001b[0m rev\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(rev)\n\u001b[0;32m     10\u001b[0m corpus\u001b[38;5;241m.\u001b[39mappend(rev)\n",
      "File \u001b[1;32mc:\\Users\\huzef\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw(fileids))\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\huzef\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(f) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[38;5;241m.\u001b[39mappend(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32mc:\\Users\\huzef\\anaconda3\\Lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root\u001b[38;5;241m.\u001b[39mjoin(file)\u001b[38;5;241m.\u001b[39mopen(encoding)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\huzef\\anaconda3\\Lib\\site-packages\\nltk\\data.py:325\u001b[0m, in \u001b[0;36mFileSystemPathPointer.open\u001b[1;34m(self, encoding)\u001b[0m\n\u001b[0;32m    323\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     stream \u001b[38;5;241m=\u001b[39m SeekableUnicodeStreamReader(stream, encoding)\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\huzef\\anaconda3\\Lib\\site-packages\\nltk\\data.py:1121\u001b[0m, in \u001b[0;36mSeekableUnicodeStreamReader.__init__\u001b[1;34m(self, stream, encoding, errors)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rewind_numchars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The number of characters that have been returned since the\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;124;03m   read that started at ``_rewind_checkpoint``.  This is used,\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;124;03m   together with ``_rewind_checkpoint``, to backtrack to the\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;124;03m   beginning of ``linebuffer`` (which is required by ``tell()``).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_bom()\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The length of the byte order marker at the beginning of\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;124;03m   the stream (or None for no byte order marker).\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\huzef\\anaconda3\\Lib\\site-packages\\nltk\\data.py:1494\u001b[0m, in \u001b[0;36mSeekableUnicodeStreamReader._check_bom\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1490\u001b[0m bom_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_BOM_TABLE\u001b[38;5;241m.\u001b[39mget(enc)\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bom_info:\n\u001b[0;32m   1493\u001b[0m     \u001b[38;5;66;03m# Read a prefix, to check against the BOM(s)\u001b[39;00m\n\u001b[1;32m-> 1494\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m   1495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1497\u001b[0m     \u001b[38;5;66;03m# Check for each possible BOM.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "corpus=[]\n",
    "for i in range(0,len(msg)):\n",
    "    rev=re.sub('[^a-zA-Z]',' ',msg['title'][i])\n",
    "    rev=rev.lower()\n",
    "    rev=rev.split()\n",
    "    rev=[ps.stem(word)for word in rev if not word in stopwords.words('english')]\n",
    "    rev=' '.join(rev)\n",
    "    corpus.append(rev)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16b3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unbeliev obama attorney gener say charlott rioter peac protest home state north carolina video'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4876c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf05307",
   "metadata": {},
   "source": [
    "One Hot Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81725e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22148,\n",
       " 63990,\n",
       " 54897,\n",
       " 25031,\n",
       " 26282,\n",
       " 43419,\n",
       " 55584,\n",
       " 49319,\n",
       " 65167,\n",
       " 30594,\n",
       " 17489,\n",
       " 23661]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_repres=[one_hot(words,voc_size)for words in corpus]\n",
    "onehot_repres[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ffe97",
   "metadata": {},
   "source": [
    "Padding : MAke all sentences of equal len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bac68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_len=20\n",
    "paddded_docs=pad_sequences(onehot_repres,padding='pre',maxlen=sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5903d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0, 22148,\n",
       "       63990, 54897, 25031, 26282, 43419, 55584, 49319, 65167, 30594,\n",
       "       17489, 23661])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddded_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e2591f",
   "metadata": {},
   "source": [
    "Creating a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566c2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huzef\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "vector_feature=40  \n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,vector_feature,input_length=sent_len))\n",
    "model.add(Dropout(0.3))\n",
    "#model.add(LSTM(100))\n",
    "#for bidirectional\n",
    "model.add(Bidirectional(LSTM(100)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8bcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73177, (73177,))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paddded_docs),y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50dcd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cc6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final=np.array(paddded_docs)\n",
    "#y_final=np.array(y)` is converting the list `y` into a NumPy array and assigning it to the variable `y_final`. This can be useful for further processing or analysis that requires NumPy arrays instead of lists.\n",
    "y_final=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code snippet is performing label encoding on a list of labels `y`.\n",
    "# Convert everything to string first\n",
    "#y contains a mix of string float  and int to converting it to int\n",
    "y_cleaned = [str(label).strip().lower() for label in y]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_cleaned)\n",
    "y_final = np.array(y_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bc13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb84c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8243b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((73177, 20), (73177,))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_final.shape,y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d647031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_final,y_final,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d824ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d45aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: -851.5170 - val_accuracy: 6.8325e-05 - val_loss: -2466.2891\n",
      "Epoch 2/10\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: -2993.6736 - val_accuracy: 6.8325e-05 - val_loss: -4455.9814\n",
      "Epoch 3/10\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: -5113.0142 - val_accuracy: 6.8325e-05 - val_loss: -6442.7642\n",
      "Epoch 4/10\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: -7053.5376 - val_accuracy: 6.8325e-05 - val_loss: -8442.0449\n",
      "Epoch 5/10\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: -9039.2822 - val_accuracy: 6.8325e-05 - val_loss: -10445.4922\n",
      "Epoch 6/10\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: -11562.2686 - val_accuracy: 6.8325e-05 - val_loss: -12470.9746\n",
      "Epoch 7/10\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: -13097.7842 - val_accuracy: 6.8325e-05 - val_loss: -14514.7969\n",
      "Epoch 8/10\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: -14915.5264 - val_accuracy: 6.8325e-05 - val_loss: -16548.0781\n",
      "Epoch 9/10\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: -17234.0605 - val_accuracy: 6.8325e-05 - val_loss: -18559.0605\n",
      "Epoch 10/10\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: -19453.6523 - val_accuracy: 6.8325e-05 - val_loss: -20562.7031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fc2f6024e0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de624d9d",
   "metadata": {},
   "source": [
    "Performanece metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a92445",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.where(y_pred>0.6,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5b4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0, 6835,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e5b4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.832467887400929e-05"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418ba9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      1.00      0.00         1\n",
      "           4       0.00      0.00      0.00      6835\n",
      "           5       0.00      0.00      0.00       200\n",
      "          10       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00      7051\n",
      "          22       0.00      0.00      0.00       198\n",
      "          24       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.00      0.00      0.00         1\n",
      "          66       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         126       0.00      0.00      0.00         1\n",
      "         129       0.00      0.00      0.00         1\n",
      "         136       0.00      0.00      0.00         1\n",
      "         145       0.00      0.00      0.00         1\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         1\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         160       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         1\n",
      "         171       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         1\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       0.00      0.00      0.00         1\n",
      "         178       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         1\n",
      "         181       0.00      0.00      0.00         1\n",
      "         193       0.00      0.00      0.00         1\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00         1\n",
      "         197       0.00      0.00      0.00         1\n",
      "         204       0.00      0.00      0.00         1\n",
      "         208       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.00      0.00      0.00         1\n",
      "         231       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         1\n",
      "         242       0.00      0.00      0.00         1\n",
      "         257       0.00      0.00      0.00         2\n",
      "         260       0.00      0.00      0.00         1\n",
      "         263       0.00      0.00      0.00         1\n",
      "         271       0.00      0.00      0.00         1\n",
      "         276       0.00      0.00      0.00         1\n",
      "         279       0.00      0.00      0.00         1\n",
      "         282       0.00      0.00      0.00         1\n",
      "         285       0.00      0.00      0.00         1\n",
      "         288       0.00      0.00      0.00         1\n",
      "         289       0.00      0.00      0.00         1\n",
      "         290       0.00      0.00      0.00         1\n",
      "         291       0.00      0.00      0.00         1\n",
      "         297       0.00      0.00      0.00         1\n",
      "         300       0.00      0.00      0.00         1\n",
      "         302       0.00      0.00      0.00         1\n",
      "         303       0.00      0.00      0.00         1\n",
      "         308       0.00      0.00      0.00         1\n",
      "         309       0.00      0.00      0.00         1\n",
      "         310       0.00      0.00      0.00         1\n",
      "         311       0.00      0.00      0.00         1\n",
      "         312       0.00      0.00      0.00         1\n",
      "         313       0.00      0.00      0.00         1\n",
      "         316       0.00      0.00      0.00         1\n",
      "         318       0.00      0.00      0.00         1\n",
      "         326       0.00      0.00      0.00         1\n",
      "         327       0.00      0.00      0.00         1\n",
      "         331       0.00      0.00      0.00         1\n",
      "         334       0.00      0.00      0.00         1\n",
      "         342       0.00      0.00      0.00         1\n",
      "         344       0.00      0.00      0.00         1\n",
      "         348       0.00      0.00      0.00         1\n",
      "         349       0.00      0.00      0.00         1\n",
      "         351       0.00      0.00      0.00         1\n",
      "         356       0.00      0.00      0.00         1\n",
      "         360       0.00      0.00      0.00         1\n",
      "         365       0.00      0.00      0.00         1\n",
      "         368       0.00      0.00      0.00         1\n",
      "         371       0.00      0.00      0.00         1\n",
      "         373       0.00      0.00      0.00         1\n",
      "         374       0.00      0.00      0.00         1\n",
      "         381       0.00      0.00      0.00         2\n",
      "         382       0.00      0.00      0.00         1\n",
      "         384       0.00      0.00      0.00         1\n",
      "         385       0.00      0.00      0.00         1\n",
      "         390       0.00      0.00      0.00         1\n",
      "         394       0.00      0.00      0.00         1\n",
      "         396       0.00      0.00      0.00         1\n",
      "         402       0.00      0.00      0.00         1\n",
      "         407       0.00      0.00      0.00         1\n",
      "         411       0.00      0.00      0.00         1\n",
      "         413       0.00      0.00      0.00         2\n",
      "         416       0.00      0.00      0.00         1\n",
      "         423       0.00      0.00      0.00         1\n",
      "         424       0.00      0.00      0.00         1\n",
      "         429       0.00      0.00      0.00         1\n",
      "         433       0.00      0.00      0.00         1\n",
      "         438       0.00      0.00      0.00         1\n",
      "         440       0.00      0.00      0.00         2\n",
      "         441       0.00      0.00      0.00         1\n",
      "         443       0.00      0.00      0.00         1\n",
      "         444       0.00      0.00      0.00         1\n",
      "         447       0.00      0.00      0.00         1\n",
      "         453       0.00      0.00      0.00         1\n",
      "         454       0.00      0.00      0.00         1\n",
      "         457       0.00      0.00      0.00         1\n",
      "         459       0.00      0.00      0.00         1\n",
      "         462       0.00      0.00      0.00         1\n",
      "         465       0.00      0.00      0.00         1\n",
      "         473       0.00      0.00      0.00         1\n",
      "         478       0.00      0.00      0.00         1\n",
      "         479       0.00      0.00      0.00         1\n",
      "         486       0.00      0.00      0.00         1\n",
      "         494       0.00      0.00      0.00         1\n",
      "         497       0.00      0.00      0.00         2\n",
      "         503       0.00      0.00      0.00         2\n",
      "         504       0.00      0.00      0.00         1\n",
      "         505       0.00      0.00      0.00         1\n",
      "         515       0.00      0.00      0.00         1\n",
      "         516       0.00      0.00      0.00         1\n",
      "         520       0.00      0.00      0.00         1\n",
      "         522       0.00      0.00      0.00         1\n",
      "         526       0.00      0.00      0.00         1\n",
      "         528       0.00      0.00      0.00         1\n",
      "         529       0.00      0.00      0.00         1\n",
      "         536       0.00      0.00      0.00         1\n",
      "         540       0.00      0.00      0.00         1\n",
      "         541       0.00      0.00      0.00         1\n",
      "         542       0.00      0.00      0.00         1\n",
      "         546       0.00      0.00      0.00         1\n",
      "         548       0.00      0.00      0.00         1\n",
      "         551       0.00      0.00      0.00         1\n",
      "         553       0.00      0.00      0.00         1\n",
      "         558       0.00      0.00      0.00         1\n",
      "         563       0.00      0.00      0.00         1\n",
      "         566       0.00      0.00      0.00         1\n",
      "         576       0.00      0.00      0.00         1\n",
      "         577       0.00      0.00      0.00         1\n",
      "         581       0.00      0.00      0.00         1\n",
      "         590       0.00      0.00      0.00         1\n",
      "         598       0.00      0.00      0.00         1\n",
      "         599       0.00      0.00      0.00         1\n",
      "         604       0.00      0.00      0.00         1\n",
      "         609       0.00      0.00      0.00         1\n",
      "         611       0.00      0.00      0.00         1\n",
      "         615       0.00      0.00      0.00         1\n",
      "         617       0.00      0.00      0.00         1\n",
      "         622       0.00      0.00      0.00         1\n",
      "         625       0.00      0.00      0.00         1\n",
      "         627       0.00      0.00      0.00         1\n",
      "         636       0.00      0.00      0.00         1\n",
      "         646       0.00      0.00      0.00         1\n",
      "         647       0.00      0.00      0.00         1\n",
      "         652       0.00      0.00      0.00         1\n",
      "         655       0.00      0.00      0.00         1\n",
      "         664       0.00      0.00      0.00         1\n",
      "         675       0.00      0.00      0.00         1\n",
      "         676       0.00      0.00      0.00         1\n",
      "         690       0.00      0.00      0.00         1\n",
      "         693       0.00      0.00      0.00         1\n",
      "         702       0.00      0.00      0.00         1\n",
      "         705       0.00      0.00      0.00         1\n",
      "         712       0.00      0.00      0.00         1\n",
      "         718       0.00      0.00      0.00         1\n",
      "         719       0.00      0.00      0.00         1\n",
      "         726       0.00      0.00      0.00         1\n",
      "         729       0.00      0.00      0.00         1\n",
      "         733       0.00      0.00      0.00         1\n",
      "         735       0.00      0.00      0.00         1\n",
      "         740       0.00      0.00      0.00         1\n",
      "         744       0.00      0.00      0.00         1\n",
      "         747       0.00      0.00      0.00         1\n",
      "         751       0.00      0.00      0.00         1\n",
      "         754       0.00      0.00      0.00         1\n",
      "         763       0.00      0.00      0.00         1\n",
      "         769       0.00      0.00      0.00         1\n",
      "         774       0.00      0.00      0.00         1\n",
      "         775       0.00      0.00      0.00         1\n",
      "         785       0.00      0.00      0.00         1\n",
      "         786       0.00      0.00      0.00         1\n",
      "         787       0.00      0.00      0.00         1\n",
      "         788       0.00      0.00      0.00         1\n",
      "         789       0.00      0.00      0.00         1\n",
      "         791       0.00      0.00      0.00         2\n",
      "         793       0.00      0.00      0.00         1\n",
      "         794       0.00      0.00      0.00         1\n",
      "         795       0.00      0.00      0.00         1\n",
      "         807       0.00      0.00      0.00         1\n",
      "         813       0.00      0.00      0.00         1\n",
      "         822       0.00      0.00      0.00         1\n",
      "         823       0.00      0.00      0.00         1\n",
      "         824       0.00      0.00      0.00         1\n",
      "         837       0.00      0.00      0.00         1\n",
      "         840       0.00      0.00      0.00         1\n",
      "         844       0.00      0.00      0.00         1\n",
      "         845       0.00      0.00      0.00         1\n",
      "         849       0.00      0.00      0.00         1\n",
      "         862       0.00      0.00      0.00         1\n",
      "         864       0.00      0.00      0.00         1\n",
      "         865       0.00      0.00      0.00         1\n",
      "         871       0.00      0.00      0.00         1\n",
      "         873       0.00      0.00      0.00         1\n",
      "         876       0.00      0.00      0.00         1\n",
      "         880       0.00      0.00      0.00         1\n",
      "         896       0.00      0.00      0.00         1\n",
      "         898       0.00      0.00      0.00         1\n",
      "         899       0.00      0.00      0.00         2\n",
      "         901       0.00      0.00      0.00         1\n",
      "         904       0.00      0.00      0.00         1\n",
      "         905       0.00      0.00      0.00         1\n",
      "         907       0.00      0.00      0.00         1\n",
      "         913       0.00      0.00      0.00         1\n",
      "         914       0.00      0.00      0.00         1\n",
      "         917       0.00      0.00      0.00         1\n",
      "         918       0.00      0.00      0.00         1\n",
      "         921       0.00      0.00      0.00         1\n",
      "         929       0.00      0.00      0.00         1\n",
      "         934       0.00      0.00      0.00         1\n",
      "         935       0.00      0.00      0.00         1\n",
      "         944       0.00      0.00      0.00         1\n",
      "         947       0.00      0.00      0.00         1\n",
      "         952       0.00      0.00      0.00         1\n",
      "         956       0.00      0.00      0.00         1\n",
      "         962       0.00      0.00      0.00         2\n",
      "         973       0.00      0.00      0.00         1\n",
      "         978       0.00      0.00      0.00         1\n",
      "         981       0.00      0.00      0.00         1\n",
      "         992       0.00      0.00      0.00         1\n",
      "         995       0.00      0.00      0.00         1\n",
      "         999       0.00      0.00      0.00         1\n",
      "        1001       0.00      0.00      0.00         1\n",
      "        1007       0.00      0.00      0.00         3\n",
      "        1009       0.00      0.00      0.00         1\n",
      "        1017       0.00      0.00      0.00         2\n",
      "        1027       0.00      0.00      0.00         1\n",
      "        1032       0.00      0.00      0.00         1\n",
      "        1033       0.00      0.00      0.00         1\n",
      "        1044       0.00      0.00      0.00         1\n",
      "        1046       0.00      0.00      0.00         1\n",
      "        1048       0.00      0.00      0.00         1\n",
      "        1049       0.00      0.00      0.00         1\n",
      "        1054       0.00      0.00      0.00         1\n",
      "        1060       0.00      0.00      0.00         1\n",
      "        1061       0.00      0.00      0.00         1\n",
      "        1062       0.00      0.00      0.00         1\n",
      "        1066       0.00      0.00      0.00         1\n",
      "        1071       0.00      0.00      0.00         1\n",
      "        1074       0.00      0.00      0.00         1\n",
      "        1075       0.00      0.00      0.00         1\n",
      "        1079       0.00      0.00      0.00         1\n",
      "        1083       0.00      0.00      0.00         1\n",
      "        1088       0.00      0.00      0.00         1\n",
      "        1090       0.00      0.00      0.00         1\n",
      "        1096       0.00      0.00      0.00         1\n",
      "        1099       0.00      0.00      0.00         1\n",
      "        1129       0.00      0.00      0.00         1\n",
      "        1137       0.00      0.00      0.00         1\n",
      "        1145       0.00      0.00      0.00         1\n",
      "        1147       0.00      0.00      0.00         1\n",
      "        1150       0.00      0.00      0.00         1\n",
      "        1154       0.00      0.00      0.00         1\n",
      "        1155       0.00      0.00      0.00         1\n",
      "        1157       0.00      0.00      0.00         1\n",
      "        1162       0.00      0.00      0.00         1\n",
      "        1165       0.00      0.00      0.00         1\n",
      "        1166       0.00      0.00      0.00         1\n",
      "        1167       0.00      0.00      0.00         1\n",
      "        1170       0.00      0.00      0.00         1\n",
      "        1184       0.00      0.00      0.00         1\n",
      "        1190       0.00      0.00      0.00         1\n",
      "        1196       0.00      0.00      0.00         1\n",
      "        1197       0.00      0.00      0.00         1\n",
      "        1208       0.00      0.00      0.00         1\n",
      "        1225       0.00      0.00      0.00         1\n",
      "        1227       0.00      0.00      0.00         1\n",
      "        1237       0.00      0.00      0.00         1\n",
      "        1238       0.00      0.00      0.00         1\n",
      "        1239       0.00      0.00      0.00         1\n",
      "        1241       0.00      0.00      0.00         1\n",
      "        1243       0.00      0.00      0.00         1\n",
      "        1250       0.00      0.00      0.00         1\n",
      "        1251       0.00      0.00      0.00         1\n",
      "        1263       0.00      0.00      0.00         1\n",
      "        1271       0.00      0.00      0.00         1\n",
      "        1280       0.00      0.00      0.00         1\n",
      "        1281       0.00      0.00      0.00         1\n",
      "        1288       0.00      0.00      0.00         1\n",
      "        1290       0.00      0.00      0.00         1\n",
      "        1291       0.00      0.00      0.00         1\n",
      "        1292       0.00      0.00      0.00         1\n",
      "        1301       0.00      0.00      0.00         1\n",
      "        1305       0.00      0.00      0.00         2\n",
      "        1308       0.00      0.00      0.00         1\n",
      "        1317       0.00      0.00      0.00         1\n",
      "        1319       0.00      0.00      0.00         1\n",
      "        1320       0.00      0.00      0.00         1\n",
      "        1321       0.00      0.00      0.00         1\n",
      "        1324       0.00      0.00      0.00         1\n",
      "        1328       0.00      0.00      0.00         1\n",
      "        1335       0.00      0.00      0.00         1\n",
      "        1340       0.00      0.00      0.00         1\n",
      "        1344       0.00      0.00      0.00         1\n",
      "        1345       0.00      0.00      0.00         1\n",
      "        1347       0.00      0.00      0.00         1\n",
      "        1348       0.00      0.00      0.00         1\n",
      "        1354       0.00      0.00      0.00         1\n",
      "        1356       0.00      0.00      0.00         1\n",
      "        1357       0.00      0.00      0.00         1\n",
      "        1360       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00     14636\n",
      "   macro avg       0.00      0.00      0.00     14636\n",
      "weighted avg       0.00      0.00      0.00     14636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huzef\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\huzef\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\huzef\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde66630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
